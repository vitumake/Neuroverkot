{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "- Read the input data\n",
    "- Convert the input data to a format that can be used by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load the Iris dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "\n",
    "# Load the dataset into a pandas dataframe\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "iris_data = pd.read_csv(url, header=None, names=column_names)\n",
    "\n",
    "# Convert species to numeric values\n",
    "iris_data['species'] = iris_data['species'].astype('category').cat.codes\n",
    "\n",
    "# Split the data into features and target\n",
    "X = iris_data.iloc[:, :-1].values\n",
    "Y = to_categorical(iris_data.iloc[:, -1].values)\n",
    "\n",
    "# Convert data to between 0-1\n",
    "X = X / X.max(axis=0)\n",
    "\n",
    "# Shuffle the dataset\n",
    "X, Y = shuffle(X, Y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "- Create a model that can be used to predict the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                50        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential([\n",
    "    Input(shape=(4,)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "- Train the model using the training data\n",
    "- Evaluate the model using the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.2982 - accuracy: 0.9667 - val_loss: 0.3254 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2935 - accuracy: 0.9750 - val_loss: 0.3224 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2899 - accuracy: 0.9750 - val_loss: 0.3156 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2865 - accuracy: 0.9750 - val_loss: 0.3120 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2826 - accuracy: 0.9750 - val_loss: 0.3074 - val_accuracy: 1.0000\n",
      "Training acc: 0.98\n",
      "Validation acc: 1.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model with validation split\n",
    "history = model.fit(X, Y, epochs=5, batch_size=5, validation_split=0.2)\n",
    "\n",
    "# Print the training and validation accuracy\n",
    "train_acc = history.history['accuracy'][-1]\n",
    "val_acc = history.history['val_accuracy'][-1]\n",
    "print(f\"Training acc: {train_acc:.2f}\")\n",
    "print(f\"Validation acc: {val_acc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
